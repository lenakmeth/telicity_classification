{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, RobertaForSequenceClassification, \\\n",
    "AlbertForSequenceClassification, XLNetForSequenceClassification, CamembertForSequenceClassification, \\\n",
    "FlaubertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, \\\n",
    "BertTokenizer, RobertaTokenizer, AlbertTokenizer, XLNetTokenizer, CamembertTokenizer, FlaubertTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_pad(transformer_model, sentences):\n",
    "    \"\"\" We are using .encode_plus. This does not make specialized attn masks \n",
    "        like in our selectional preferences experiment. Revert to .encode if\n",
    "        necessary.\"\"\"\n",
    "    \n",
    "    input_ids = []\n",
    "    segment_ids = [] # token type ids\n",
    "    attention_masks = []\n",
    "    \n",
    "    if transformer_model.split(\"-\")[0] == 'bert':\n",
    "        tok = BertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'roberta':\n",
    "        tok = RobertaTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'albert':\n",
    "        tok = AlbertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'xlnet':\n",
    "        tok = XLNetTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'camembert' in transformer_model:\n",
    "        tok = CamembertTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'flaubert' in transformer_model:\n",
    "        tok = FlaubertTokenizer.from_pretrained(transformer_model)\n",
    "\n",
    "    for sent in sentences:\n",
    "        sentence = sent[0]\n",
    "\n",
    "        # encode_plus is a prebuilt function that will make input_ids, \n",
    "        # add padding/truncate, add special tokens, + make attention masks \n",
    "        encoded_dict = tok.encode_plus(\n",
    "                        sentence,                      \n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,      # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True, # Construct attn. masks.\n",
    "                        # return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # Add segment ids, add 1 for verb idx\n",
    "        segment_id = encoded_dict['token_type_ids']\n",
    "        segment_id[sent[2]] = 1\n",
    "        segment_ids.append(segment_id)\n",
    "\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    return input_ids, attention_masks, segment_ids\n",
    "\n",
    "\n",
    "def decode_result(transformer_model, encoded_sequence):\n",
    "\n",
    "    if transformer_model.split(\"-\")[0] == 'bert':\n",
    "        tok = BertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'roberta':\n",
    "        tok = RobertaTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'albert':\n",
    "        tok = AlbertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'xlnet':\n",
    "        tok = XLNetTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'camembert' in transformer_model:\n",
    "        tok = CamembertTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'flaubert' in transformer_model:\n",
    "        tok = FlaubertTokenizer.from_pretrained(transformer_model)\n",
    "    \n",
    "    # decode + remove special tokens\n",
    "    tokens_to_remove = ['[PAD]', '<pad>', '<s>', '</s>']\n",
    "    decoded_sequence = [w.replace('Ġ', '').replace('▁', '').replace('</w>', '')\n",
    "                        for w in list(tok.convert_ids_to_tokens(encoded_sequence))\n",
    "                        if not w.strip() in tokens_to_remove]\n",
    "    \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load finetuned model\n",
    "\n",
    "tokenizer_model = 'albert-base-v2'\n",
    "verb_segment_ids = 'no'\n",
    "model_save_path = 'checkpoints/friedrich_captions_data/telicity/'\n",
    "\n",
    "if tokenizer_model.split(\"-\")[0] == 'bert':\n",
    "    model = BertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif tokenizer_model.split(\"-\")[0] == 'roberta':\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif tokenizer_model.split(\"-\")[0] == 'albert':\n",
    "    model = AlbertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif tokenizer_model.split(\"-\")[0] == 'xlnet':\n",
    "    model = XLNetForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif 'camembert' in tokenizer_model:\n",
    "    model = CamembertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif 'flaubert' in tokenizer_model:\n",
    "    model = FlaubertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open unseen test set\n",
    "\n",
    "test_sentences = {}\n",
    "test_labels = {}\n",
    "    \n",
    "with open('data/unseen_tests/ukwac_telic_sents.tsv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split('\\t')\n",
    "        verb = lemmatizer.lemmatize(l[-3], pos='v')\n",
    "        if verb == 'cutted':\n",
    "            verb = 'cut'\n",
    "        elif verb == 'fell':\n",
    "            verb = 'fall'\n",
    "        if not verb in test_sentences:\n",
    "            test_sentences[verb] = []\n",
    "            test_labels[verb] = []\n",
    "        test_sentences[verb].append([l[1], l[-3], int(l[-2])])\n",
    "        test_labels[verb].append(0)\n",
    "\n",
    "with open('data/unseen_tests/ukwac_atelic_sents.tsv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split('\\t')\n",
    "        verb = lemmatizer.lemmatize(l[-3], pos='v')\n",
    "        if verb == 'felt':\n",
    "            verb = 'feel'\n",
    "        elif verb == 'sitted':\n",
    "            verb = 'sit'\n",
    "        elif verb == 'saw':\n",
    "            verb = 'see'\n",
    "        if not verb in test_sentences:\n",
    "            test_sentences[verb] = []\n",
    "            test_labels[verb] = []\n",
    "        test_sentences[verb].append([l[1], l[-3], int(l[-2])])\n",
    "        test_labels[verb].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for verb in test_sentences:\n",
    "#     print(verb, '\\t', len(test_sentences[verb]), '\\t', ('telic' if test_labels[verb][0] == 0 else 'atelic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = 'stay'\n",
    "\n",
    "use_segment_ids = False\n",
    "test_inputs, test_masks, test_segments = tokenize_and_pad(tokenizer_model, test_sentences[verb][:100])\n",
    "\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "test_labels = torch.tensor(test_labels[verb][:100])\n",
    "test_masks = torch.tensor(test_masks)\n",
    "test_segments = torch.tensor(test_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return attentions for each sentence of the test set, attentions per sentence (not batched per layer)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_inputs = []\n",
    "sent_attentions = []\n",
    "sentences = []\n",
    "predicted_labels = []\n",
    "prob_prediction = []\n",
    "\n",
    "for inputs in test_inputs:\n",
    "    \n",
    "    test_input = inputs.resize(1, 128)\n",
    "    \n",
    "    with torch.no_grad():        \n",
    "        outputs = model(test_input, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=None)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    attentions = outputs[1]\n",
    "    \n",
    "    log_probs = F.softmax(Variable(torch.from_numpy(logits)), dim=-1)\n",
    "\n",
    "    predicted_labels += np.argmax(logits, axis=1).flatten().tolist()\n",
    "    prob_prediction += log_probs.tolist()\n",
    "    \n",
    "    sentence = decode_result(tokenizer_model, inputs)\n",
    "    sentences.append(sentence)\n",
    "    len_sequence = len(sentence)\n",
    "    \n",
    "    temp_attentions = [] # turn attention to (layer, head, size, size)\n",
    "    \n",
    "    for layer in attentions:\n",
    "        temp = torch.squeeze(layer) #remove dimension of batch size = 1\n",
    "        temp = np.array(temp)[:, :len_sequence, :len_sequence]\n",
    "        temp_attentions.append(temp)\n",
    "        \n",
    "    sent_attentions.append(np.asarray(temp_attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg telic: 0.32642980813980105\n",
      "avg atelic: 0.6735702002048493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7105a06ef0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "\n",
    "all_telic_probs = [x[0] for x in prob_prediction]\n",
    "all_atelic_probs = [x[1] for x in prob_prediction]\n",
    "\n",
    "print('avg telic:', sum(all_telic_probs)/len(all_telic_probs))\n",
    "print('avg atelic:', sum(all_atelic_probs)/len(all_atelic_probs))\n",
    "\n",
    "plt.title('Probabibility of tag for verb: ' + verb)\n",
    "\n",
    "plt.bar(list(range(len(all_telic_probs))), [1 for n in all_telic_probs])\n",
    "plt.bar(list(range(len(all_atelic_probs))), sorted(all_atelic_probs))\n",
    "plt.legend(['telic', 'atelic'])\n",
    "# plt.plot(list(range(len(all_telic_probs))), sorted(all_telic_probs))\n",
    "# plt.plot(list(range(len(all_atelic_probs))), sorted(all_atelic_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
