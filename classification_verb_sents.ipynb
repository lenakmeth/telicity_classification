{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, RobertaForSequenceClassification, \\\n",
    "AlbertForSequenceClassification, XLNetForSequenceClassification, CamembertForSequenceClassification, \\\n",
    "FlaubertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, \\\n",
    "BertTokenizer, RobertaTokenizer, AlbertTokenizer, XLNetTokenizer, CamembertTokenizer, FlaubertTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_pad(transformer_model, sentences):\n",
    "    \"\"\" We are using .encode_plus. This does not make specialized attn masks \n",
    "        like in our selectional preferences experiment. Revert to .encode if\n",
    "        necessary.\"\"\"\n",
    "    \n",
    "    input_ids = []\n",
    "    segment_ids = [] # token type ids\n",
    "    attention_masks = []\n",
    "    \n",
    "    if transformer_model.split(\"-\")[0] == 'bert':\n",
    "        tok = BertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'roberta':\n",
    "        tok = RobertaTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'albert':\n",
    "        tok = AlbertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'xlnet':\n",
    "        tok = XLNetTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'camembert' in transformer_model:\n",
    "        tok = CamembertTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'flaubert' in transformer_model:\n",
    "        tok = FlaubertTokenizer.from_pretrained(transformer_model)\n",
    "\n",
    "    for sent in sentences:\n",
    "        sentence = sent[0]\n",
    "\n",
    "        # encode_plus is a prebuilt function that will make input_ids, \n",
    "        # add padding/truncate, add special tokens, + make attention masks \n",
    "        encoded_dict = tok.encode_plus(\n",
    "                        sentence,                      \n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,      # Pad & truncate all sentences.\n",
    "                        padding = 'max_length',\n",
    "                        truncation = True,\n",
    "                        return_attention_mask = True, # Construct attn. masks.\n",
    "                        # return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # Add segment ids, add 1 for verb idx\n",
    "        segment_id = encoded_dict['token_type_ids']\n",
    "        segment_id[sent[2]] = 1\n",
    "        segment_ids.append(segment_id)\n",
    "\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    return input_ids, attention_masks, segment_ids\n",
    "\n",
    "\n",
    "def decode_result(transformer_model, encoded_sequence):\n",
    "\n",
    "    if transformer_model.split(\"-\")[0] == 'bert':\n",
    "        tok = BertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'roberta':\n",
    "        tok = RobertaTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'albert':\n",
    "        tok = AlbertTokenizer.from_pretrained(transformer_model)\n",
    "    elif transformer_model.split(\"-\")[0] == 'xlnet':\n",
    "        tok = XLNetTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'camembert' in transformer_model:\n",
    "        tok = CamembertTokenizer.from_pretrained(transformer_model)\n",
    "    elif 'flaubert' in transformer_model:\n",
    "        tok = FlaubertTokenizer.from_pretrained(transformer_model)\n",
    "    \n",
    "    # decode + remove special tokens\n",
    "    tokens_to_remove = ['[PAD]', '<pad>', '<s>', '</s>']\n",
    "    decoded_sequence = [w.replace('Ġ', '').replace('▁', '').replace('</w>', '')\n",
    "                        for w in list(tok.convert_ids_to_tokens(encoded_sequence))\n",
    "                        if not w.strip() in tokens_to_remove]\n",
    "    \n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load finetuned model\n",
    "\n",
    "tokenizer_model = 'albert-base-v2'\n",
    "verb_segment_ids = 'no'\n",
    "model_save_path = 'checkpoints/friedrich_captions_data/telicity/'\n",
    "\n",
    "if tokenizer_model.split(\"-\")[0] == 'bert':\n",
    "    model = BertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif tokenizer_model.split(\"-\")[0] == 'roberta':\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif tokenizer_model.split(\"-\")[0] == 'albert':\n",
    "    model = AlbertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif tokenizer_model.split(\"-\")[0] == 'xlnet':\n",
    "    model = XLNetForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif 'camembert' in tokenizer_model:\n",
    "    model = CamembertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)\n",
    "elif 'flaubert' in tokenizer_model:\n",
    "    model = FlaubertForSequenceClassification.from_pretrained(model_save_path + tokenizer_model + '_' + verb_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open unseen test set\n",
    "\n",
    "test_sentences = {}\n",
    "test_labels = {}\n",
    "    \n",
    "with open('data/unseen_tests/ukwac_telic_sents.tsv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split('\\t')\n",
    "        verb = lemmatizer.lemmatize(l[-3], pos='v')\n",
    "        if verb == 'cutted':\n",
    "            verb = 'cut'\n",
    "        elif verb == 'fell':\n",
    "            verb = 'fall'\n",
    "        if not verb in test_sentences:\n",
    "            test_sentences[verb] = []\n",
    "            test_labels[verb] = []\n",
    "        test_sentences[verb].append([l[0], l[-3], int(l[-2])])\n",
    "        test_labels[verb].append(0)\n",
    "\n",
    "with open('data/unseen_tests/ukwac_atelic_sents.tsv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split('\\t')\n",
    "        verb = lemmatizer.lemmatize(l[-3], pos='v')\n",
    "        if verb == 'felt':\n",
    "            verb = 'feel'\n",
    "        elif verb == 'sitted':\n",
    "            verb = 'sit'\n",
    "        elif verb == 'saw':\n",
    "            verb = 'see'\n",
    "        if not verb in test_sentences:\n",
    "            test_sentences[verb] = []\n",
    "            test_labels[verb] = []\n",
    "        test_sentences[verb].append([l[0], l[-3], int(l[-2])])\n",
    "        test_labels[verb].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "look \t 110998 \t telic\n",
      "[[\"the next page looks like this : tick the box next to ' remember my organization next time i login ' , then click ' continue ' .\", 'looks', 3], ['we look at consumer , non consumer and international transactions .', 'look', 1], ['we also look at how some marketing calls could result in some hefty fines .', 'look', 2], [\"next time - we 'll look at the business case for rss - the ' ultimate permission marketing tool ' .\", 'look', 5], ['these monsters only look out for themselves and don? $ t care about the old tribes .', 'look', 3]]\n",
      "\n",
      "open \t 30895 \t telic\n",
      "[['this opens up whole new possibilities .', 'opens', 1], ['when i opened my door in the evening , off they would go with a squeak and a bounce .', 'opened', 2], ['confronted by this drascombe broadside the first pleasure palace opened the throttle still further and belching mightily went for the only gap .', 'opened', 9], ['it opens with very deep bass notes , beautiful trumpet work , all very quiet .', 'opens', 1], ['the value of competitive research awards and contracts currently open in the biology department exceeds # 20million .', 'open', 9]]\n",
      "\n",
      "give \t 148467 \t telic\n",
      "[['this gave less anode current than expected , because the anode had spilt some electrons while accepting others .', 'gave', 1], ['the stress of working and job hunting had given her two colds and one flu already .', 'given', 8], ['better still give them a call .', 'give', 2], ['bibliography the cabinet gave him special responsibility for the campaign ( a land assault at the straits ) but no powers of direction .', 'gave', 3], ['general examination may give corroborating evidence of significant ingestions or clues in unknown overdoses .', 'give', 3]]\n",
      "\n",
      "fall \t 28130 \t telic\n",
      "[['so the anode current falls .', 'falls', 4], [\"however , the proportion opting for defined contribution provision has fallen from 97 % in watson wyatt 's 2002 survey to 73 % in the latest survey .\", 'fallen', 10], ['a deep silence fell upon the mob .', 'fell', 3], ['5 ) six of the customary tenements fell vacant at the black death , ( fn .', 'fell', 7], ['donald fell unconscious because of all the excitement .', 'fell', 1]]\n",
      "\n",
      "cut \t 8517 \t telic\n",
      "[['a low battery cut out ( microprocessor controlled charging circuit ) provides long battery life .', 'cut', 3], ['you can also cut body fat for the same effect .', 'cut', 3], ['we cut the premium , not the cover .', 'cut', 1], ['a cake board . click here using the small knife cut the cake as shown above .', 'cut', 10], [\"'' daniel cut off his words , closed his eyes and breathed a weary sigh .\", 'cut', 2]]\n",
      "\n",
      "close \t 10446 \t telic\n",
      "[[\"'' '' british steel closed the ravenscraig steel works in scotland with 17,000 job losses .\", 'closed', 4], ['it closes at the end of february 2006 .', 'closes', 1], [\"gordon pursglove , head of esf division , who chaired the seminar , closed the day 's proceedings .\", 'closed', 13], ['it closes something of a masterpiece work as a whole .', 'closes', 1], ['the hospital finally closed in 1995 .', 'closed', 3]]\n",
      "\n",
      "drop \t 9626 \t telic\n",
      "[['the performance of standard cooling systems can drop by 30-50 % over time as the cooling membranes get dirty .', 'drop', 7], ['a u.s. warplane dropped a bomb along the border after a rogue pakistani border guard shot and wounded an american soldier .', 'dropped', 3], ['dan schneider from the single man affair drops by and gives us rendiditon of a previously unreleased song .', 'drops', 7], ['50 ) the income from the market tolls dropped during the 14th century , ( fn .', 'dropped', 8], ['( the other two drop their smile ) . voice 3 : they what ?', 'drop', 4]]\n",
      "\n",
      "break \t 11641 \t telic\n",
      "[[\"our new products break through the mass market clutter to deliver distinctive toys that inspire the imagination and bring out a child 's true character .\", 'break', 3], ['if your family breaks up , joint tenants and married partners have certain rights to stay .', 'breaks', 3], ['he broke into the cafe , but set off an alarm .', 'broke', 1], [\"traicos 's 22 years broke the test record of george gunn , who did not play for england between 1912 and 1930 .\", 'broke', 4], ['after two years he returned to salzburg broke and disappointed .', 'broke', 7]]\n",
      "\n",
      "shoot \t 4045 \t telic\n",
      "[['every hand in the class shot up .', 'shot', 5], [\"'' '' general hammond gave me a chance , '' daniel shot back .\", 'shot', 11], ['2 . do you shoot reportage or traditional .', 'shoot', 4], ['i shoot traditional with a few action shots .', 'shoot', 1], [\"'' '' why did he shoot him ?\", 'shoot', 5]]\n",
      "\n",
      "arrest \t 906 \t telic\n",
      "[['we do not arrest the wrong person .', 'arrest', 3], [\"stalin 's agents routinely arrested and killed as '' enemies of the people '' anyone who disagreed with his politics .\", 'arrested', 4], ['samuel strides forth to arrest the mummy .', 'arrest', 4], ['police arrested the driver , who later failed a breath test 42 .', 'arrested', 1], ['they eventually arrested and charged three suspects 51 days later .', 'arrested', 2]]\n",
      "\n",
      "see \t 236541 \t atelic\n",
      "[['please see here for a list of our facilities .', 'see', 1], ['for more details about this and other developments content see find out more', 'see', 9], ['before you can see the book you must save it to your computer .', 'see', 3], ['the final results saw the overall top ten places dominated by the vintage fleet who had impressed all with their ability .', 'saw', 3], [\"to see some of ian 's excellent images , click here\", 'see', 1]]\n",
      "\n",
      "stay \t 11660 \t atelic\n",
      "[['stayed with a friend in amherst late fall bout ten years ago .', 'stayed', 0], ['how to stay young 1 . throw out nonessential numbers .', 'stay', 2], ['yavlinsky has stayed out of power under yeltsin and become one of his harshest critics .', 'stayed', 2], ['school stay city outreach tram for new communities social care team staff and health care team .', 'stay', 1], [\"children 's services stay or members of new refugee communities clear or refugee action .\", 'stay', 3]]\n",
      "\n",
      "know \t 94449 \t atelic\n",
      "[[\"you do n't know bill troper do you ?\", 'know', 3], ['the community pastoral care pastoral care pastoral care within a comparatively small 24\\\\/7 residential community such as ours , people know one another well .', 'know', 20], ['we do not know the name of this gallant man we salute him - we salute his family - we salute all who suffered likewise .', 'know', 3], ['you never know in the future !', 'know', 2], [\"do you know something we do n't ?\", 'know', 2]]\n",
      "\n",
      "begin \t 41025 \t atelic\n",
      "[['the pilot began on 9 september on the a41 finchley road during normal bus lane operating hours .', 'began', 2], ['each day begins at about 8am ( yikes !', 'begins', 2], ['it begins close to birchwood station and skirts the edge of oakwood and gorse covert , before heading for risley along daten avenue .', 'begins', 1], [\"he began to spray it , and to sora 's surprise it melted away .\", 'began', 1], ['it began with the youngest who wrapped a box put her picture on the outside .', 'began', 1]]\n",
      "\n",
      "visit \t 24882 \t atelic\n",
      "[['he visited the crimea in 1921 .', 'visited', 1], ['for more detailed information and photos visit the site below .', 'visit', 6], ['to visit the project website please click here', 'visit', 1], ['visit the bgs online shop .', 'visit', 0], ['as rich hall the stand-up , he has visited the edinburgh fringe festival several times and performed at the major comedy clubs in britain and across the world .', 'visited', 8]]\n",
      "\n",
      "improve \t 15082 \t atelic\n",
      "[['improves synthesis of b vitamins in the gut .', 'improves', 0], ['the addition of beneficial bacteria can improve the digestive system by balancing the bacteria load in the intestines .', 'improve', 6], ['selenium together with vitamin e improves antibody production and response so can improve immune function .', 'improves', 5], ['the ability to grow fish very rapidly improves the economics of our . . .', 'improves', 7], ['her sense of direction has not improved .', 'improved', 6]]\n",
      "\n",
      "feel \t 45638 \t atelic\n",
      "[[\"but do n't feel too sorry for them .\", 'feel', 3], ['career changers at home with the cat feel that they have all day to do easier things than career change slavery .', 'feel', 7], [\"maria also felt that : '' camelot 's volunteers got a lot from the day too .\", 'felt', 2], [\"the tigers and dolphins in siegfried &amp; roy 's secret garden and dolphin habitat feel right at home in this tropical environment .\", 'feel', 14], ['and how does the child feel ?', 'feel', 5]]\n",
      "\n",
      "lie \t 20883 \t atelic\n",
      "[[\"lowland single malt south of edinburgh , in th eheart of gentlemen-farmers ' land lies the glenkinchie distillery .\", 'lies', 14], ['at the root of these problems lies a disastrous period of economic reforms .', 'lies', 6], ['their institutional basis lies in the pressures of such a university towards disciplinarity .', 'lies', 3], ['yet at the heart of this matter lie some profoundly human ( if no less complex ) questions .', 'lie', 7], ['4 . the summit of blencathra lies 500m ssw across the grassy summit plateau .', 'lies', 6]]\n",
      "\n",
      "believe \t 32802 \t atelic\n",
      "[['therefore manifest believes that these recommendations for the first time give active cross-border investors a tool with which to request the background for informed decision-making and dialogue .', 'believes', 2], ['we all believe in everything we do 100 percent .', 'believe', 2], ['we believe this technology has applications not only in cars but also in many other display products .', 'believe', 1], ['of course some believe we can simply rest on our laurels .', 'believe', 3], ['no-one seriously believes that a centrally controlled policy for agriculture makes sense today .', 'believes', 2]]\n",
      "\n",
      "sit \t 19587 \t atelic\n",
      "[['sitting in a good sized plot .', 'sitting', 0], ['europe can sit back and admire its history as it watches the world go by .', 'sit', 2], ['david sits on education and martin on social care and housing .', 'sits', 1], ['rob and david also sit on the shipley area committee .', 'sit', 4], ['sitting area with comfortable and stylish sofas , open fire .', 'sitting', 0]]\n",
      "\n",
      "admire \t 1470 \t atelic\n",
      "[[\"'' what current chart rivals do you most admire ?\", 'admire', 8], ['he genuinely admired the french extremists .', 'admired', 2], ['you can admire the wonders of their counting system in the maori diagram .', 'admire', 2], [\"we admired the fact that shushkevich gave up voluntarily belarus ' nuclear arsenal .\", 'admired', 1], ['whilst we look on these , we admire not observations of coals found fresh after four hundred years .', 'admire', 7]]\n",
      "\n",
      "lay \t 10437 \t atelic\n",
      "[['the imf has laid down strict criteria for receiving the international loans promised to russia by clinton , kohl and other western leaders .', 'laid', 3], ['experience of a certain kind lay before me , on no narrow scale .', 'lay', 5], ['pythons lay eggs in clutches varying from only a few to almost a hundred eggs , depending on the size and species of the snake .', 'lay', 1], ['miles laid out themes and a few chords and the band improvised around them .', 'laid', 1], ['davis laid out the themes and chords before the tape rolled , and then the band improvised .', 'laid', 1]]\n",
      "\n",
      "laugh \t 2400 \t atelic\n",
      "[['she laughed , shook her curls from her eyes , and danced away as if i had paid her a compliment .', 'laughed', 1], ['laughed at everything from the very beginning .', 'laughed', 0], [\"'' he laughs in cynical astonishment .\", 'laughs', 2], ['laughing falcon ( herpetotheres cachinnans ) on 8-08 2 exx . in the pantanal .', 'laughing', 0], ['i laughed more when the twin towers collapsed .', 'laughed', 1]]\n",
      "\n",
      "live \t 40408 \t atelic\n",
      "[['some live in the eastern hemisphere , including madagascar and the solomon islands .', 'live', 1], ['do you live in the area named and shamed above ?', 'live', 2], ['i live in the birkenhead area ( near liverpool ) so no-where over 4 hours away .', 'live', 1], ['how long do clones live ?', 'live', 4], ['and he lives among the dead .', 'lives', 2]]\n",
      "\n",
      "allow \t 24823 \t atelic\n",
      "[['and regulations allow senators in support interest in the dealer f amp .', 'allow', 2], ['many other products allow borrowers to pay-down lump sums without suffering a penalty .', 'allow', 3], ['the teacher toolkit allows you to store selected activities into a designated teacher area .', 'allows', 3], ['6-speed , close ratio manual gearbox allows 60 mph in first gear , 100 mph cruising at 2,450 rpm in 6th .', 'allows', 6], ['this system allows one to identify the natural classes defined within a linear model ( namely in terms of the + \\\\/ - values ) .', 'allows', 2]]\n",
      "\n",
      "stand \t 29357 \t atelic\n",
      "[[\"from the whitewashed huer 's hut , still standing above the harbor .\", 'standing', 8], ['then stand back and admire .', 'stand', 1], ['it really stands out because sifu hartsell does not simply give us a bunch of random grappling techniques .', 'stands', 2], [\"'' how much pleasure can you stand ?\", 'stand', 6], ['2 ) what does the acronym eniac stand for ?', 'stand', 7]]\n",
      "\n",
      "realize \t 6996 \t atelic\n",
      "[[\"you realize that it does n't have the power to destroy you .\", 'realize', 1], ['just realize that the bigger the number , the stronger the bond .', 'realize', 1], [\"he may have realized the great importance of unitary representations after wigner 's book , group theory with applications to atomic spectroscopy .\", 'realized', 3], ['i realize none of this clears the matter up , but i hope it explains the confusion !', 'realize', 1], ['with what i just learned from your manual , i realize that i left a lot of money on the table .', 'realize', 10]]\n",
      "\n",
      "prepare \t 8594 \t atelic\n",
      "[['prepare and maintain systems protocols and documentation ; develop , monitor and review business processes linked to the applications .', 'prepare', 0], ['if you do not have a mandolin , you can prepare the vegetables by hand .', 'prepare', 10], ['further study the ba ( hons ) theatre practice course prepares you for a career in the performance industries and for postgraduate study .', 'prepares', 10], ['preparing the data ( the easy way ) euroscore reads a csv format data file , in a specific layout .', 'preparing', 0], ['she prepares and processes budgetry information , provides general administrative support and coordination , and maintains the computerized recording system .', 'prepares', 1]]\n",
      "\n",
      "thrive \t 1337 \t atelic\n",
      "[['science thrives on skeptical inquiry into new ideas .', 'thrives', 1], ['despite the tragedy in their lives , the boys thrived .', 'thrived', 9], ['churches have long thrived under that subtle thumbscrew of forced loyalty .', 'thrived', 3], [\"( reads further ) ' count celia thrives in the pony club trials and that little freddy scores a century for the first eleven ' .\", 'thrives', 7], ['tourism thrives on a high quality natural and built environment .', 'thrives', 1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for verb in test_sentences:\n",
    "    print(verb, '\\t', len(test_sentences[verb]), '\\t', ('telic' if test_labels[verb][0] == 0 else 'atelic'))\n",
    "    print(test_sentences[verb][:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = 'stay'\n",
    "\n",
    "use_segment_ids = False\n",
    "test_inputs, test_masks, test_segments = tokenize_and_pad(tokenizer_model, test_sentences[verb][:100])\n",
    "\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "test_labels = torch.tensor(test_labels[verb][:100])\n",
    "test_masks = torch.tensor(test_masks)\n",
    "test_segments = torch.tensor(test_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/melodi/emetheni/.local/lib/python3.6/site-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "# Return attentions for each sentence of the test set, attentions per sentence (not batched per layer)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_inputs = []\n",
    "sent_attentions = []\n",
    "sentences = []\n",
    "predicted_labels = []\n",
    "prob_prediction = []\n",
    "\n",
    "for inputs in test_inputs:\n",
    "    \n",
    "    test_input = inputs.resize(1, 128)\n",
    "    \n",
    "    with torch.no_grad():        \n",
    "        outputs = model(test_input, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=None)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    attentions = outputs[1]\n",
    "    \n",
    "    log_probs = F.softmax(Variable(torch.from_numpy(logits)), dim=-1)\n",
    "\n",
    "    predicted_labels += np.argmax(logits, axis=1).flatten().tolist()\n",
    "    prob_prediction += log_probs.tolist()\n",
    "    \n",
    "    sentence = decode_result(tokenizer_model, inputs)\n",
    "    sentences.append(sentence)\n",
    "    len_sequence = len(sentence)\n",
    "    \n",
    "    temp_attentions = [] # turn attention to (layer, head, size, size)\n",
    "    \n",
    "    for layer in attentions:\n",
    "        temp = torch.squeeze(layer) #remove dimension of batch size = 1\n",
    "        temp = np.array(temp)[:, :len_sequence, :len_sequence]\n",
    "        temp_attentions.append(temp)\n",
    "        \n",
    "    sent_attentions.append(np.asarray(temp_attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg telic: 0.3262496092915535\n",
      "avg atelic: 0.673750387430191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f56ef7ee780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "\n",
    "all_telic_probs = [x[0] for x in prob_prediction]\n",
    "all_atelic_probs = [x[1] for x in prob_prediction]\n",
    "\n",
    "print('avg telic:', sum(all_telic_probs)/len(all_telic_probs))\n",
    "print('avg atelic:', sum(all_atelic_probs)/len(all_atelic_probs))\n",
    "\n",
    "plt.title('Probabibility of tag for verb: ' + verb)\n",
    "\n",
    "plt.bar(list(range(len(all_telic_probs))), [1 for n in all_telic_probs])\n",
    "plt.bar(list(range(len(all_atelic_probs))), sorted(all_atelic_probs))\n",
    "plt.legend(['telic', 'atelic'])\n",
    "# plt.plot(list(range(len(all_telic_probs))), sorted(all_telic_probs))\n",
    "# plt.plot(list(range(len(all_atelic_probs))), sorted(all_atelic_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
